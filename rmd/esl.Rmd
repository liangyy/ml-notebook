---
title: "ESL reading notes"
date: "`r format(Sys.time(), '%d %B, %Y')`"
---

# Chapter 2

* 2.1 - 2.5 [note](c2_21_25.html)
* 2.6 [note](c2_6.html)
* 2.7 [note](c2_7.html): Very insightful overview on why we want to have structured regression models.
* 2.8 [note](c2_8.html): Overview of restricted estimators.
* 2.9 [note](c2_9.html): Model selection and the Bias-Variance tradeoff.

# Chapter 3

* 3.1 - 3.2.2 [note](c3_1_.html): Introduction to least squares.
* 3.2.3 - 3.2.4 [note](c3_2_cont.html): Least squares with multiple $X$ or $Y$.
* 3.3 [note](c3_3.html): Subset selection.
* 3.4.1 [note](c3_4.html): Ridge regression.
* 3.4.2 - 3.4.3 [note](c3_4_2.html): Lasso and the geometric view.
* 3.4.4 [note](c3_4_4.html): Least angle regression.
* 3.5 - 3.6 [note](c3_5.html): Using derived input directions.
* 3.7 [note](c3_7.html): Multiple outcomes. 
* 3.8 [note](c3_8.html): More algorithms on Lasso and brief on computational cost.
